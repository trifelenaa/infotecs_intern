# -*- coding: utf-8 -*-
"""train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FOq2_odbVDHHpGwZ1mCVboNDjNNhQ4Cz
"""

# импорт необходимых библиотек
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
import joblib

# загрузка тренировочных данных
train_data = pd.read_csv('train.tsv', sep='\t')

# создание векторизатора для представления текста в цифровом формате
vectorizer = CountVectorizer(token_pattern=r'\b\w+\b')

# векторизация тренировочных данных и выделение меток для обучения
X_train = vectorizer.fit_transform(train_data['libs'])
y_train = train_data['is_virus']

# обучение нескольких моделей для выявления лучшей

# отмечу, что в изначальном коде использовался GridSearchCV, но дабы не загромождать код,
# я сразу использовала здесь best_params_

# мультиномиальный наивный байесовский метод
model_multinb = MultinomialNB()
model_multinb.fit(X_train, y_train)

# логистическая регрессия
model_log = LogisticRegression(C = 5, penalty = 'l2', solver = 'liblinear')
model_log.fit(X_train, y_train)

# градиентный бустинг
model_boost = GradientBoostingClassifier(criterion='squared_error', learning_rate= 0.1, loss= 'log_loss', n_estimators= 300)
model_boost.fit(X_train, y_train)

# сохранение модели в файл
joblib.dump(model_multinb, 'model_multinb.joblib')
joblib.dump(model_log, 'model_log.joblib')
joblib.dump(model_boost, 'model_boost.joblib')
joblib.dump(vectorizer, 'vectorizer.joblib')