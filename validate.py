# -*- coding: utf-8 -*-
"""validate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zKOod6MmfS-yXJ_1mmFl-EiXxbml4tak
"""

import pandas as pd
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
import joblib

# загрузка валидационных данных
val_data = pd.read_csv('val.tsv', sep='\t')

# загрузка модели и векторизатора из файлов
model_multinb= joblib.load('model_multinb.joblib')
model_log= joblib.load('model_log.joblib')
model_boost= joblib.load('model_boost.joblib')
vectorizer = joblib.load('vectorizer.joblib')

# напишем функцию для подсчета всех необходимых метрик (чтобы было удобно использовать для нескольких моделей)
def count_val_metrics (model, data):

  # предсказание на валидационной выборке
  X_val = vectorizer.transform(val_data['libs'])
  y_val = val_data['is_virus']
  val_pred = model.predict(X_val)

  #расчет всех метрик
  cm = confusion_matrix(y_val, val_pred)
  tn, fp, fn, tp = confusion_matrix(y_val, val_pred).ravel()
  accuracy = accuracy_score(y_val, val_pred)
  precision = precision_score(y_val, val_pred)
  recall = recall_score(y_val, val_pred)
  f1 = f1_score(y_val, val_pred)
  return cm, tn, fp, fn, tp, accuracy, precision, recall, f1

# функция записи результатов на валидационной выборке в файл validation.txt для лучшей модели
def create_val_file(tn, fp, fn, tp,accuracy,precision,recall, f1):
  with open('validation.txt', 'w') as f:
    f.write(f'True positive: {tp}\n')
    f.write(f'False positive: {fp}\n')
    f.write(f'False negative: {fn}\n')
    f.write(f'True negative: {tn}\n')
    f.write(f'Accuracy: {accuracy:.4f}\n')
    f.write(f'Precision: {precision:.4f}\n')
    f.write(f'Recall: {recall:.4f}\n')
    f.write(f'F1: {f1:.4f}\n')

#для трех моделей получаем все необходимые параметры (да, их много..)
cm_multinb, tn_multinb, fp_multinb, fn_multinb, tp_multinb, accuracy_multinb, precision_multinb, recall_multinb, f1_multinb = count_val_metrics(model_multinb, val_data)
cm_log, tn_log, fp_log, fn_log, tp_log, accuracy_log, precision_log, recall_log, f1_log = count_val_metrics(model_log, val_data)
cm_boost, tn_boost, fp_boost, fn_boost, tp_boost, accuracy_boost, precision_boost, recall_boost, f1_boost = count_val_metrics(model_boost, val_data)

#далее выполним некоторую визуализацию данных

#построим матрицы ошибок для всех моделей
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 3, figsize=(25, 7))

disp1 = ConfusionMatrixDisplay(confusion_matrix = cm_multinb,
                               display_labels=[False, True]).plot(ax=ax[0]);

ax[0].set_title('Multinomial Naive Bayes')

disp2 = ConfusionMatrixDisplay(confusion_matrix = cm_log,
                               display_labels=[False, True]).plot(ax=ax[1]);

ax[1].set_title('Logistic Regression')

disp3 = ConfusionMatrixDisplay(confusion_matrix = cm_boost,
                               display_labels=[False, True]).plot(ax=ax[2]);

ax[2].set_title('Gradient Boosting')

#сохраняем результаты в файл, чтобы можно было ознакомиться
plt.savefig('confusion_matrixes.png')

#построим таблицу со значениями метрик с выделением максимального
accuracy = [accuracy_multinb, accuracy_log, accuracy_boost]
precision = [precision_multinb, precision_log, precision_boost]
recall = [recall_multinb, recall_log, recall_boost]
f1 = [f1_multinb, f1_log, f1_boost]

list_tuples = list(zip(accuracy, precision, recall, f1))

df = pd.DataFrame(list_tuples,
                  index = ['MultinomialNB','LogisticRegression','GradientBoostingClassifier'],
                  columns=['Accuracy', 'Precision', 'Recall', 'F1'])


styled_df = df.style.highlight_max(axis = 0, color='pink')

#сохраняем результаты в файл Excel, чтобы не потерять форматирование
#результаты указывают нам на то, что модель Градиентного Бустинга имеет оптимальные показатели (даже если они не максимальные, то очень близки к ним, и в сравнении бустинг выигрывает)
with pd.ExcelWriter('table_of_metrics.xlsx', engine='openpyxl') as writer:
    styled_df.to_excel(writer, index=False)

#для лучшей модели выполним запись метрик в файл validation.txt
create_val_file(tn_boost, fp_boost, fn_boost, tp_boost, accuracy_boost, precision_boost, recall_boost, f1_boost)